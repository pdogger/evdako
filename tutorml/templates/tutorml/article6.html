{% extends 'tutorml/article.html' %}
{% load static %}

{% block title %}
{{ article.title }}
{% endblock %}

{% block links %}
<link rel="stylesheet" href="{% static 'tutorml/css/forms.css' %}">
<link rel="stylesheet" href="{% static 'tutorml/css/atropos.min.css' %}">
<link rel="stylesheet" href="{% static 'tutorml/css/parallax.css' %}">
{% endblock %}

{% block content %}
<section class="section full_article">
    <div class="article parallax_article">
        <div class="atropos parallax">
            <!-- scale container (required) -->
            <div class="atropos-scale">
              <!-- rotate container (required) -->
              <div class="atropos-rotate">
                <!-- inner container (required) -->
                <div class="atropos-inner">
                    <img data-atropos-offset="-5" src="{% static article.img_path %}">
                    <h1 class="text-over" data-atropos-offset="3">{{ article.title }}</h1>
                    <div class="article_info text-over-2" data-atropos-offset="3">
                        <span>{{ article.category }}</span>
                        <span>{{ article.pub_date }}</span>
                    </div>
                </div>
              </div>
            </div>
        </div>
    </div>
    <div class="mobile_article">
        <h1 class="section_title">{{ article.title }}</h1>
        <div class="article">
            <div class="article_img"><img src="{% static article.img_path %}"></div>
            <div class="article_info">
                <span>{{ article.category }}</span>
                <span>{{ article.pub_date }}</span>
            </div>
        </div>
    </div>
    <div class="article_text">
        <p>
            В последние годы машинный перевод стал одной из ключевых тем в
            области ИИ, и крупные компании начали гонку по запуску собственных сервисов машинного перевода.
        </p>
        <p>
            В этой статье мы обучим свою модель машинного перевода: Модель трансформера.
        </p>
        <p>
            Трансформер - это модель глубокого обучения, которая была впервые предложена в 2017 году.
            Она использует механизм "внимания", который повышает производительность приложений нейронного
            машинного перевода по сравнению с традиционной моделью рекуррентной нейронной сети и,
            следовательно, ускоряет процесс обучения в задачах обработки естественного языка (NLP).
        </p>
        <p>
            Для начала нам нужно загрузить данные для обучения
        </p>

        <pre class="prettyprint lang-py linenums">
from datasets import load_dataset, load_metric

raw_datasets = load_dataset("wmt16", "ru-en")
metric = load_metric("sacrebleu")
        </pre>

        <p>
            Прежде чем мы сможем подать эти тексты в нашу модель, их необходимо предварительно обработать.
             Для этого используется Transformers Tokenizer, который (как видно из названия) токенизирует
            входные данные (включая преобразование токенов в соответствующие им идентификаторы в
            предварительно подготовленном словаре) и помещает их в формат, ожидаемый моделью, а также
            генерирует другие входные данные, необходимые модели.
        </p>
        <pre class="prettyprint lang-py linenums">
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)

max_input_length = 128
max_target_length = 128
source_lang = "en"
target_lang = "ru"

def preprocess_function(examples):
    inputs = [prefix + ex[source_lang] for ex in examples["translation"]]
    targets = [ex[target_lang] for ex in examples["translation"]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)

    # Setup the tokenizer for targets
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=True)

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs
        </pre>

        <p>
            Теперь, когда наши данные готовы, мы можем загрузить модель и
            провести ее настройку. Поскольку наша задача относится к типу
            sequence-to-sequence, мы используем класс AutoModelForSeq2SeqLM.
            Как и в случае с токенизатором, метод from_pretrained загрузит и
            кэширует модель для нас.
        </p>
        <pre class="prettyprint lang-py linenums">
from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq,
                         Seq2SeqTrainingArguments, Seq2SeqTrainer

model_checkpoint = "Helsinki-NLP/opus-mt-en-ru"
model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)

batch_size = 16
model_name = model_checkpoint.split("/")[-1]
args = Seq2SeqTrainingArguments(
    f"{model_name}-finetuned-{source_lang}-to-{target_lang}",
    evaluation_strategy = "epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=1,
    predict_with_generate=True,
    fp16=True,
    push_to_hub=True,
)
        </pre>

        <p>
            Последнее, что нужно определить для нашего Seq2SeqTrainer, это
            как вычислять метрики из предсказаний. Для этого нам нужно
            определить функцию, которая будет просто использовать метрику,
            загруженную нами ранее, и мы должны сделать небольшую
            предварительную обработку для декодирования предсказаний в тексты:
        </p>


        <pre class="prettyprint lang-py linenums">
import numpy as np

def postprocess_text(preds, labels):
    preds = [pred.strip() for pred in preds]
    labels = [[label.strip()] for label in labels]

    return preds, labels

def compute_metrics(eval_preds):
    preds, labels = eval_preds
    if isinstance(preds, tuple):
        preds = preds[0]
    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)

    # Replace -100 in the labels as we can't decode them.
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Some simple post-processing
    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    result = {"bleu": result["score"]}

    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]
    result["gen_len"] = np.mean(prediction_lens)
    result = {k: round(v, 4) for k, v in result.items()}
    return result
        </pre>

        <p>
            Затем нам просто нужно передать все это вместе с нашим набором данных в Seq2SeqTrainer:
        </p>


        <pre class="prettyprint lang-py linenums">
trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()
        </pre>


        <p>
            Ниже расположена формочка, в которой вы можете ввести свой текст
            на русском языке, чтобы проверить, правильно ли описанная модель
            переведет его на английский. Спасибо за внимание!
        </p>

    </div>
    <form class="form_predict_lang" method="POST">
        {% csrf_token %}
        <textarea id="text_translate_text" placeholder="Введите текст для перевода"></textarea>
        <button id="translate_text" type="submit">Перевести</button>
        <p id="translated_text"></p>
    </form>
</section>
<audio autoplay hidden loop id="audio_article">
    <source src="{% static 'tutorml/audio/back.mp3' %}" type="audio/mpeg">
    Ваш браузер не поддерживает проигрыш аудио.
</audio>
{% endblock %}

{% block scripts %}
<script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<script src="{% static 'tutorml/js/atropos.min.js' %}"></script>
<script>
    document.getElementById("audio_article").volume = 0.05;
</script>
<script>
    $("#translate_text").click(function () {
        var input = $('#text_translate_text').val();
        var token = $(".form_predict_lang").find('input[name=csrfmiddlewaretoken]').val();

        $.ajax({
            url: "{% url 'tutorml:translate_text' %}",
            method: 'post',
            data: {
                'inputValue': input,
                'csrfmiddlewaretoken': token,
            },
            dataType: 'json',
            success: function (data) {
                document.getElementById('translated_text').innerHTML = data["response"];
                document.getElementById('translated_text').style.display = 'block';
            }
        });
        event.preventDefault();
    });
    const parallax = Atropos({
        el: '.parallax',
        rotateXMax: 25,
        rotateYMax: 25,
        shadow: false
    });
</script>
{% endblock %}